
# modules/sorgu_iylestir.py ‚Äî verbose + clamp non-improvements to 0% change
from __future__ import annotations
import os, json, re, time
import pandas as pd
from sentence_transformers import SentenceTransformer, util

# ============== CONFIG (edit here) ==============
MIN_IMPROVE = 0.0003               # ~0.03% absolute relative improvement
MAX_ATTEMPTS = 3                   # try up to N; if not improved, add anyway with 0% change
ONLY_IMPROVED = False              # do NOT skip non-improved rows
OLLAMA_MODEL = "gemma3:4b"
# ===============================================

# ---- paths ----
try:
    from config import output_dir as _OUT
except Exception:
    _OUT = os.path.join("data", "output")
os.makedirs(_OUT, exist_ok=True)

SORGU_IN_CSV  = os.path.join(_OUT, "icerik_sorgu_top10.csv")
SORGU_OUT_CSV = os.path.join(_OUT, "icerik_sorgu_iyilestirme.csv")

# ---- model ----
try:
    from config import model as _cfg_model  # instance or callable
    st_model = _cfg_model() if callable(_cfg_model) else _cfg_model
except Exception:
    st_model = SentenceTransformer("emrecan/bert-base-turkish-cased-mean-nli-stsb-tr")

# prompt builder (use user's module if available)
try:
    from prompt.sorgu_prompt import generate_sorgu_prompt as _gen_sorgu_prompt
except Exception:
    _gen_sorgu_prompt = None

# ============== UTIL ==============
def now() -> str:
    return time.strftime("%H:%M:%S", time.localtime())

def fmt_sec(s: float) -> str:
    if s < 1: return f"{s*1000:.0f} ms"
    m, r = divmod(s, 60)
    return f"{int(m)}m {r:.1f}s" if m >= 1 else f"{s:.2f} s"

def _read_csv_robust(path: str) -> pd.DataFrame:
    t0 = time.time()
    print(f"[{now()}] ‚¨áÔ∏è  Reading CSV: {path}", flush=True)
    for enc in (None, "utf-8", "utf-8-sig", "latin-1"):
        try:
            df = pd.read_csv(path, encoding=enc) if enc else pd.read_csv(path)
            print(f"[{now()}] ‚úÖ CSV loaded ({len(df)} rows) in {fmt_sec(time.time()-t0)}", flush=True)
            return df
        except Exception:
            continue
    raise RuntimeError(f"CSV okunamadƒ±: {path}")

def _pick_col(df: pd.DataFrame, names):
    low = {c.lower(): c for c in df.columns}
    for n in names:
        if n in df.columns: return n
        if n.lower() in low: return low[n.lower()]
    def norm(s): return re.sub(r"[ƒ∞Iƒ±]", "i", s, flags=re.I).lower()
    norm_map = {norm(c): c for c in df.columns}
    for n in names:
        if norm(n) in norm_map: return norm_map[norm(n)]
    return None

def _norm_score(x) -> float:
    s = str(x if x is not None else "").replace("%","").replace(",",".").strip()
    m = re.findall(r"[-+]?\d*\.?\d+", s)
    if not m: return 0.0
    v = float(m[0])
    return round(v/100.0, 6) if v > 1.5 else round(v, 6)

def _similarity(a_text: str, b_text: str) -> float:
    if not a_text or not b_text: return 0.0
    a = st_model.encode(a_text, convert_to_tensor=True, normalize_embeddings=True)
    b = st_model.encode(b_text, convert_to_tensor=True, normalize_embeddings=True)
    return float(util.cos_sim(a, b).item())

def _run_llm(prompt: str) -> str:
    from ollama import chat
    t0 = time.time()
    print(f"[{now()}] üîÅ LLM call ‚Üí {OLLAMA_MODEL} (chars: {len(prompt)})", flush=True)
    resp = chat(model=OLLAMA_MODEL, messages=[{"role": "user", "content": prompt}])
    out = resp.get("message", {}).get("content", str(resp))
    print(f"[{now()}] ‚úÖ LLM done in {fmt_sec(time.time()-t0)}", flush=True)
    return out

def _parse_llm_json(text: str) -> dict:
    m = re.search(r"\{.*\}", text, flags=re.S)
    if not m: raise ValueError("LLM yanƒ±tƒ±nda JSON bulunamadƒ±.")
    return json.loads(m.group(0))

# ---- prompt builders ----
SORGU_SYS = (
    "Sen bir SEO ve i√ßerik geli≈ütirme uzmanƒ±sƒ±n. "
    "G√∂revin, kullanƒ±cƒ± sorgusuna g√∂re mevcut metni k√º√ß√ºk dokunu≈ülarla iyile≈ütirmek. "
    "h1/h2: sorguyu doƒürudan kar≈üƒ±layan ba≈ülƒ±k; p/div: +5‚Äì10 kelime; li: +1‚Äì2 kelime. "
    "Anlamƒ± bozma, pazarlama kli≈üeleri ekleme. Sadece ge√ßerli JSON d√∂nd√ºr."
)
SORGU_HUM = """
Girdi:
Kullanƒ±cƒ± Sorgusu: "{query}"
Mevcut ƒ∞√ßerik: "{current}"
HTML B√∂l√ºm√º: "{tag}"
Eski Skor: {old}

Beklenen √ßƒ±ktƒ± (JSON):
{{
  "Kullanƒ±cƒ± Sorgusu": "{query}",
  "Eski Metin": "{current}",
  "Geli≈ütirilmi≈ü Metin": "Buraya geli≈ütirilmi≈ü hali gelecek",
  "HTML B√∂l√ºm√º": "{tag}"
}}
""".strip()

def _build_sorgu_prompt(query, current, tag, old):
    if _gen_sorgu_prompt:
        try:
            return _gen_sorgu_prompt(query, current, tag, old)
        except Exception:
            pass
    return f"{SORGU_SYS}\n{SORGU_HUM}".format(query=query, current=current, tag=tag, old=old)

# ---- core improve ----
def _try_improve(query_text, current_text, html_tag, old_score,
                 min_improve=MIN_IMPROVE, max_attempts=MAX_ATTEMPTS):
    best_text = current_text
    best_score = old_score if old_score > 0 else _similarity(query_text, current_text)

    for attempt in range(1, max_attempts+1):
        print(f"    [{now()}] attempt {attempt}/{max_attempts} | baseline={best_score:.4f}", flush=True)
        prompt = _build_sorgu_prompt(query_text, best_text, html_tag, best_score)
        data = _parse_llm_json(_run_llm(prompt))

        cand = data.get("Geli≈ütirilmi≈ü Metin")
        if not isinstance(cand, str) or not cand.strip():
            print("    ‚Ü™Ô∏è  LLM returned empty candidate; keeping current text", flush=True)
            cand = best_text

        new_score = _similarity(query_text, cand)
        print(f"    [{now()}] scored new={new_score:.4f} (delta={(new_score-best_score):+.4f})", flush=True)

        if new_score >= best_score * (1.0 + min_improve):
            print(f"    üéØ improved ‚â• {min_improve*100:.3f}% ‚Äî accepting", flush=True)
            return cand, new_score

        if new_score > best_score:
            print("    ‚¨ÜÔ∏è  slight improvement; updating baseline and retrying", flush=True)
            best_text, best_score = cand, new_score

    print("‚öñÔ∏è  no sufficient improvement; returning best so far", flush=True)
    return best_text, best_score

# ============== FLOW ==============
def run_sorgu_flow(min_improve=MIN_IMPROVE, max_attempts=MAX_ATTEMPTS, only_improved=ONLY_IMPROVED) -> str:
    t_flow = time.time()
    df = _read_csv_robust(SORGU_IN_CSV)

    c_query = _pick_col(df, ["Kullanƒ±cƒ± Sorgusu","Kullanici Sorgusu","Sorgu","Query","Aranan Sorgu"])
    c_html  = _pick_col(df, ["HTML Kaynaƒüƒ±","HTML Kaynagi","HTML B√∂l√ºm√º","HTML Section"])
    c_text  = _pick_col(df, ["Web ƒ∞√ßeriƒüi","Web Icerigi","ƒ∞√ßerik","Icerik","Metin","Content"])
    c_score = _pick_col(df, ["Benzerlik Skoru","Skor","Score","Similarity Score","similarity_score"])
    for need, name in [(c_query,"Kullanƒ±cƒ± Sorgusu"), (c_html,"HTML Kaynaƒüƒ±"), (c_text,"Web ƒ∞√ßeriƒüi")]:
        if not need: raise KeyError(f"Eksik kolon: {name}")

    total = len(df)
    kept = improved = 0
    rows = []

    print(f"[{now()}] üöÄ SORGU flow start | rows={total} | MIN_IMPROVE={min_improve} | MAX_ATTEMPTS={max_attempts}", flush=True)

    for idx, r in df.iterrows():
        r_t0 = time.time()
        q   = str(r[c_query] or "")
        tag = str(r[c_html] or "")
        cur = str(r[c_text] or "")
        old = _norm_score(r[c_score]) if c_score else _similarity(q, cur)

        print(f"\n[{now()}] ‚Üí Row {idx + 1}/{total} | tag='{tag}' | old={old:.4f}", flush=True)
        cand, new = _try_improve(q, cur, tag, old, min_improve, max_attempts)

        improved_flag = new > old
        improved += 1 if improved_flag else 0
        kept += 1
        change_pct = ((new - old) / max(old, 1e-8) * 100.0) if improved_flag else 0.0

        rows.append({
            "HTML B√∂l√ºm√º": tag,
            "Kullanƒ±cƒ± Sorgusu": q,
            "Eski Metin": cur,
            "Geli≈ütirilmi≈ü Metin": cand,
            "Eski Skor": round(float(old), 6),
            "Yeni Skor": round(float(new), 6),
            "Y√ºzde Deƒüi≈üim": round(float(change_pct), 2),
        })
        msg = "‚úÖ kept (Œî=+{:.2f}%)".format(change_pct) if improved_flag else "‚úÖ kept (no improvement; Œî=0.00%)"
        print(f"   {msg}", flush=True)
        print(f"   ‚è± row time: {fmt_sec(time.time()-r_t0)}", flush=True)

    out_df = pd.DataFrame(rows)
    out_df.to_csv(SORGU_OUT_CSV, index=False, encoding="utf-8")
    print(f"\n[{now()}] üíæ SORGU saved ‚Üí {SORGU_OUT_CSV} (rows kept={kept}, improved={improved})", flush=True)
    print(f"[{now()}] üèÅ SORGU flow finished in {fmt_sec(time.time()-t_flow)}\n", flush=True)
    return SORGU_OUT_CSV

def main():
    t_all = time.time()
    print(f"[{now()}] ‚öôÔ∏è  START sorgu_iylestir.py", flush=True)
    print(f"    INPUT : {SORGU_IN_CSV}", flush=True)
    print(f"    OUTPUT: {SORGU_OUT_CSV}", flush=True)
    run_sorgu_flow()
    print(f"[{now()}] ‚úÖ DONE", flush=True)

if __name__ == "__main__":
    main()
